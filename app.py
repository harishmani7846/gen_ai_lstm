# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pX5V0d2AE3P6svNJsBC2wQ30lTdTSzYT
"""

!pip install tensorflow scikit-learn joblib --quiet

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import joblib

# Generate numbers from 1 to 100
data = np.array([i for i in range(1, 101)]).reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# Create sequences: 3 steps in, 1 step out
X, y = [], []
for i in range(3, len(data_scaled)):
    X.append(data_scaled[i-3:i])
    y.append(data_scaled[i])

X, y = np.array(X), np.array(y)

# Reshape X for LSTM: (samples, time_steps, features)
print(X.shape)  # (97, 3, 1)

model = Sequential([
    LSTM(50, activation='relu', input_shape=(3, 1)),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')
model.fit(X, y, epochs=100, verbose=0)

print("‚úÖ Model trained.")

# Define a wrapper class that holds the model and scaler
class LSTMWrapper:
    def __init__(self, model, scaler):
        self.model = model
        self.scaler = scaler

    def predict_next(self, input_seq):
        input_scaled = self.scaler.transform(np.array(input_seq).reshape(-1, 1))
        X_input = np.array([input_scaled]).reshape((1, 3, 1))
        y_pred_scaled = self.model.predict(X_input, verbose=0)
        return self.scaler.inverse_transform(y_pred_scaled)[0][0]

# Save the full wrapper as a single pickle file
wrapped = LSTMWrapper(model, scaler)
joblib.dump(wrapped, "model.pkl")

print("üì¶ model.pkl saved!")

# Load and test
loaded = joblib.load("model.pkl")

test_input = [98, 99, 100]
predicted = loaded.predict_next(test_input)

print(f"üîÆ Predicted next number after {test_input} is: {predicted:.2f}")

import numpy as np
import joblib
import gradio as gr

# Load the saved model wrapper
model_wrapper = joblib.load("model.pkl")

def predict_next_number(num1, num2, num3):
    try:
        input_seq = [num1, num2, num3]
        prediction = model_wrapper.predict_next(input_seq)
        return f"üîÆ Predicted next number: {prediction:.2f}"
    except Exception as e:
        return f"‚ùå Error: {e}"

# Gradio Interface
interface = gr.Interface(
    fn=predict_next_number,
    inputs=[
        gr.Number(label="1st Number"),
        gr.Number(label="2nd Number"),
        gr.Number(label="3rd Number")
    ],
    outputs=gr.Textbox(label="Prediction"),
    title="üî¢ LSTM Sequence Predictor",
    description="Enter 3 numbers. The model will predict the next number using a trained LSTM model.",
    theme="default"
)

if __name__ == "__main__":
    interface.launch()
